politics
{ Yael Eisenstat 
    November 12 2019 02:30 AM
 https://www.independent.ie/opinion/comment/yael-eisenstat-as-long-as-facebook-prioritises-profit-it-cannot-avoid-damaging-democracies-38683700.html }
I joined Facebook in June 2018 as its 'head of global elections integrity ops' in the company's business integrity organisation, focused specifically on political advertising. I had spent much of my career working to strengthen and defend democracy - including freedom of speech - as an intelligence officer, diplomat and White House adviser. Now I had the opportunity to help a company I viewed as playing a major role in one of the biggest threats to our democracy to possibly correct course. In the year leading up to the United States' 2016 election, I had begun seeing the polarisation and breakdown of civil discourse, exacerbated by social media, as our biggest national security threat - I had written about that before Facebook called. I didn't think I was going to change the company, but I wanted to help Facebook think through the very challenging questions of what role it plays in politics, in the United States and around the world, and the best way to ensure it is not harming democracy. A year-and-a-half later, as the company continues to struggle with how to handle political content and as another presidential election approaches, it is clear that tinkering around the margins of advertising policies won't fix the most serious issues. The real problem is that Facebook profits partly by amplifying lies and selling dangerous targeting tools which allow political operatives to engage in a new level of information warfare. Its business model exploits our data to let advertisers custom-target people, show us each a different version of the truth and manipulate us with hyper-customised ads - ads which, as of two weeks ago, can contain blatantly false and debunked information if they are run by a political campaign. As long as Facebook prioritises profit over healthy discourse, it cannot avoid damaging democracies. Early in my time there, I dug into the question of misinformation in political advertising. Posting in a "tribe" - Facebook's internal collaboration platform - I asked our teams working on political advertising whether we should incorporate the same tools for political ads that other integrity teams at Facebook were developing to address misinformation in pages and organic posts. It was unclear to me why the company was applying different, siloed policies and tools across the platform. Most users do not differentiate organic content from ads - as I clearly saw on a trip to India, where we were testing our ad integrity products - so why were we expecting users to understand that we applied different standards to different forms of content that all just appear in their news feeds? The fact we were taking money for political ads and allowing campaigns and other political organisations to target users based on the vast amounts of data we had gathered meant political ads should have an even higher bar for integrity than what people were posting in organic content. We verified advertisers to run political ads, giving them a check mark and a "paid for by" label, and I questioned whether that gave the false impression that we were vouching for the validity of the content, boosting its perceived credibility even though we weren't checking any facts or ensuring that ads weren't spreading false information. Most of my colleagues agreed. People wanted to get this right. But, above me, there was no appetite for my pushing, and I was accused of "creating confusion". Ultimately, I was not empowered to do the job I was hired to do, and I left within six months. Couching the issue now as simply a question of free speech is both disingenuous and an intentional distraction. Many of the fixes found in the company's new ad transparency rules are laudable and necessary, but the core issue will not be solved before 2020 without addressing that fundamental systemic problem the business model causes. Sheryl Sandberg, Facebook's chief operating officer, said in an interview recently that the company is leading on transparency in political advertising and providing all the relevant information in the "ad library". But true transparency would include information about the tools which differentiate advertising on Facebook from traditional print and television, and in fact make it more dangerous: can I see if a political advertiser used the custom audience tool and, if so, if my email address was uploaded? Can I see what lookalike audience advertisers are seeking? Can I see a true, verified name of the advertiser in the disclaimer? Can I see if and how your algorithms amplified the ad? If not, the claim that Facebook is simply providing a level playing field for free expression is a myth. Free political speech is core to our democratic principles, and it is true that social media companies should not be the arbiters of truth. But the only way Facebook or other companies which use our behavioural data to potentially manipulate us through targeted advertising can prevent abuse of their platform to harm our electoral process is to end their most egregious targeting and amplification practices and provide real transparency. © Washington Post Irish Independent 
